This project is a real-time **seat occupancy detection system** that uses a webcam and the **YOLOv3 (You Only Look Once)** deep learning model through OpenCV to identify and monitor seating arrangements. It specifically detects two object classes: **persons** and **chairs**, and determines whether each chair is **occupied** or **vacant** based on the overlap between the bounding boxes of detected persons and chairs using **IoU (Intersection over Union)**. The live video feed is processed frame by frame, where each object is labeled, color-coded, and its status is displayed on screen with a visually clear outline and text box for better readability.

The system employs preprocessing techniques such as resizing, blurring, and mirroring the camera feed to enhance detection accuracy and user experience. Detected chairs and persons are separated, filtered using Non-Maximum Suppression to remove overlapping duplicates, and analyzed for occupancy. The interface shows the total number of chairs, how many are occupied, and how many remain vacant. This solution is suitable for applications like **smart classrooms**, **libraries**, **offices**, or **public seating areas**, where monitoring seat usage can improve space utilization, planning, or energy savings without the need for physical sensors.
